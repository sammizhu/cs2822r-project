{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision fastai matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install --upgrade fastai torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from fastai.vision.all import untar_data, URLs\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_path = untar_data(URLs.IMAGENETTE)\n",
    "\n",
    "print(f\"imagenet path: {imagenet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training and validation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "imagenet_train_dataset = datasets.ImageFolder(imagenet_path/'train', transform=train_transforms)\n",
    "imagenet_val_dataset = datasets.ImageFolder(imagenet_path/'val', transform=val_transforms)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "imagenet_train_loader = DataLoader(imagenet_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "imagenet_val_loader = DataLoader(imagenet_val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model (ResNet18 for example)\n",
    "def create_model(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    # Replace the final fully connected layer with the correct number of classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# ImageNet \n",
    "imagenet_model = create_model(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Adam or SGD)\n",
    "imagenet_optimizer = optim.Adam(imagenet_model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    model = model.to(device)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Compute average loss for this epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validate the model\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update correct predictions\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model on imagenet\n",
    "print(\"Training on imagenet dataset...\")\n",
    "# train_model(imagenet_model, imagenet_train_loader, imagenet_val_loader, criterion, imagenet_optimizer, num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "# torch.save(imagenet_model.state_dict(), 'imagenet_best_model.pth')\n",
    "\n",
    "# Load the models for inference\n",
    "imagenet_model.load_state_dict(torch.load('models/imagenet_best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model \n",
    "model = models.resnet18(pretrained=True)\n",
    "# num_classes = 10 \n",
    "# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store activations for multiple layers\n",
    "activations = {}\n",
    "\n",
    "# Hook function to save activations from any layer\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks on all layers that are convolutional\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):  # Only capture Conv2d layers\n",
    "        layer.register_forward_hook(get_activation(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and preprocess the dog image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    return input_tensor, image\n",
    "\n",
    "image_path = '/Users/sammizhu/cs2822r-project/images/test_imgs/chainsaw.jpg'\n",
    "\n",
    "# Load the image of your dog\n",
    "input_tensor, image = load_image(image_path)\n",
    "\n",
    "# Step 3: Load ImageNet Class Labels\n",
    "imagenet_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "imagenet_labels = requests.get(imagenet_url).json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Move the input tensor to the device\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Forward pass to get the model's output\n",
    "outputs = model(input_tensor)\n",
    "probabilities = F.softmax(outputs[0], dim=0)\n",
    "confidence, predicted_idx = torch.max(probabilities, 0)\n",
    "predicted_class = imagenet_labels[predicted_idx.item()]\n",
    "\n",
    "print(f\"Image: {image_path}, Predicted Class: {predicted_class}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "# Get the predicted class\n",
    "# target_class = output.argmax().item()\n",
    "\n",
    "# Zero out any previous gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# Backward pass to compute gradients for the target class\n",
    "outputs[0, predicted_idx].backward(retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Grad-CAM heatmap\n",
    "def grad_cam(activation, gradients):\n",
    "    # Global average pooling over the gradients (average the gradients per feature map)\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    # Multiply each channel in the activation map by the pooled gradients\n",
    "    for i in range(activation.size(1)):\n",
    "        activation[:, i, :, :] *= pooled_gradients[i]\n",
    "    # Create the heatmap by averaging the weighted activation maps\n",
    "    heatmap = torch.mean(activation, dim=1).squeeze()\n",
    "    # Apply ReLU to remove negative values and normalize the heatmap\n",
    "    heatmap = torch.relu(heatmap)\n",
    "    heatmap -= heatmap.min()\n",
    "    heatmap /= heatmap.max()\n",
    "    return heatmap.detach().cpu().numpy()\n",
    "\n",
    "# Function to save the heatmap without overlaying on the original image\n",
    "def save_heatmap_only(heatmap, layer_name, i, save_folder=\"all_layers\", colormap='jet'):\n",
    "    # Ensure save folder exists\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    # Normalize heatmap to 8-bit and resize\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_resized = cv2.resize(heatmap, (1229, 1229), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Apply colormap\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Save the heatmap as an image file\n",
    "    save_path = os.path.join(save_folder, f\"cnn_layer_{i}.png\")\n",
    "    cv2.imwrite(save_path, heatmap_colored)\n",
    "    print(f\"Saved Grad-CAM heatmap for layer '{layer_name}' to: {save_path}\")\n",
    "\n",
    "# Main function to generate Grad-CAM for all layers and save each heatmap\n",
    "def generate_gradcam_for_all_layers(activations, target_class, output, i=1):\n",
    "    for layer_name, activation in activations.items():\n",
    "        try:\n",
    "            # Compute gradients with allow_unused=True\n",
    "            gradients = torch.autograd.grad(\n",
    "                outputs=output[:, target_class], \n",
    "                inputs=activation, \n",
    "                retain_graph=True, \n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "\n",
    "            if gradients is None:\n",
    "                print(f\"No gradients found for layer: {layer_name}\")\n",
    "                continue\n",
    "\n",
    "            # Generate the Grad-CAM heatmap\n",
    "            heatmap = grad_cam(activation, gradients)\n",
    "            print(f\"Generating and saving Grad-CAM heatmap for layer: {layer_name}\")\n",
    "\n",
    "            # Save the heatmap without overlaying on the original image\n",
    "            save_heatmap_only(heatmap, layer_name, i)\n",
    "            i += 1  # Increment the layer counter for each saved image\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error processing layer {layer_name}: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "# Ensure `activations`, `target_class`, and `output` are defined\n",
    "generate_gradcam_for_all_layers(activations, predicted_idx.item(), outputs, i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def save_top_k_regions_on_gradcam(grad_cam, output_filename, top_k, save_folder=\"top_k_regions\"):\n",
    "    # Step 1: Normalize Grad-CAM to range [0, 1] if not already normalized\n",
    "    grad_cam -= grad_cam.min()\n",
    "    if grad_cam.max() > 0:\n",
    "        grad_cam /= grad_cam.max()\n",
    "\n",
    "    # Step 2: Convert Grad-CAM to 8-bit for contour detection\n",
    "    grad_cam_8bit = np.uint8(255 * grad_cam)\n",
    "\n",
    "    # Step 3: Apply thresholding to better separate regions\n",
    "    _, binary_map = cv2.threshold(grad_cam_8bit, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Step 4: Find contours representing distinct regions\n",
    "    contours, _ = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(f\"Number of contours (regions) found: {len(contours)}\")\n",
    "\n",
    "    # Step 5: Calculate intensity for each contour region using the original grad_cam values\n",
    "    contour_intensities = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        mask = np.zeros_like(grad_cam, dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, 1, thickness=-1)  # Fill contour area with 1s\n",
    "        intensity = np.sum(grad_cam * mask)  # Sum intensity within the contour\n",
    "        contour_intensities.append((contour, intensity))\n",
    "\n",
    "    # Step 6: Sort contours by intensity and select the top-k contours\n",
    "    top_k_contours = sorted(contour_intensities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Step 7: Create a mask to display only the top-k contours\n",
    "    top_k_mask = np.zeros_like(grad_cam)\n",
    "    for contour, intensity in top_k_contours:\n",
    "        print(f\"Including contour with intensity: {intensity}\")\n",
    "        cv2.drawContours(top_k_mask, [contour], -1, 1, thickness=-1)\n",
    "\n",
    "    # Step 8: Apply the mask on the Grad-CAM to isolate and display only the top-k regions\n",
    "    top_k_grad_cam = grad_cam * top_k_mask\n",
    "    top_k_grad_cam_colored = cv2.applyColorMap(np.uint8(255 * top_k_grad_cam), cv2.COLORMAP_JET)\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    save_path = os.path.join(save_folder, f\"polariod_{output_filename}_top{top_k}.png\")\n",
    "    cv2.imwrite(save_path, top_k_grad_cam_colored)\n",
    "    print(f\"Saved image with Top-{top_k} distinct Grad-CAM regions for '{output_filename}' to: {save_path}\")\n",
    "\n",
    "def process_folder_of_gradcams(gradcam_folder, top_k=1, save_folder=\"top_k_regions\"):\n",
    "    for filename in os.listdir(gradcam_folder):\n",
    "        gradcam_path = os.path.join(gradcam_folder, filename)\n",
    "        \n",
    "        # Load the Grad-CAM heatmap\n",
    "        grad_cam = cv2.imread(gradcam_path, cv2.IMREAD_GRAYSCALE) / 255.0  # Normalize the Grad-CAM\n",
    "        \n",
    "        # Check that the Grad-CAM heatmap loaded correctly\n",
    "        if grad_cam is None:\n",
    "            print(f\"Error loading {filename}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Save the Top-K distinct regions from the Grad-CAM heatmap\n",
    "        output_filename = os.path.splitext(filename)[0]  # Use filename without extension\n",
    "        save_top_k_regions_on_gradcam(grad_cam, output_filename, top_k, save_folder)\n",
    "\n",
    "# Example Usage:\n",
    "gradcam_folder = \"/cs2822r-project/images/{###}\"  # Folder containing Grad-CAM heatmap variations\n",
    "process_folder_of_gradcams(gradcam_folder, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
