{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "    return input_tensor, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Dictionary to store activations for multiple layers\n",
    "activations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook function to save activations from any layer\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks on all layers that are convolutional\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):  # We only care about Conv layers for Grad-CAM\n",
    "        layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "# Print the number of layers for reference\n",
    "print(f\"Total convolutional layers with hooks: {len(activations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Grad-CAM heatmap\n",
    "def grad_cam(activation, gradients):\n",
    "    # Global average pooling over the gradients (average the gradients per feature map)\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "    # Multiply each channel in the activation map by the pooled gradients\n",
    "    for i in range(activation.size(1)):\n",
    "        activation[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Create the heatmap by averaging the weighted activation maps\n",
    "    heatmap = torch.mean(activation, dim=1).squeeze()\n",
    "\n",
    "    # Apply ReLU to remove negative values\n",
    "    heatmap = F.relu(heatmap)\n",
    "\n",
    "    # Normalize the heatmap between 0 and 1 for visualization\n",
    "    heatmap -= heatmap.min()\n",
    "    heatmap /= heatmap.max()\n",
    "\n",
    "    return heatmap.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Function to visualize the heatmap overlayed on the original image with color\n",
    "def visualize_heatmap(img, heatmap, alpha=0.5, colormap='jet'):\n",
    "    # Resize heatmap to match the size of the original image\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    \n",
    "    # Apply colormap to the heatmap (using plt.cm.get_cmap)\n",
    "    colormap = plt.get_cmap(colormap)\n",
    "    heatmap_colored = colormap(heatmap)\n",
    "\n",
    "    # Remove the alpha channel from the colormap result (4th channel)\n",
    "    heatmap_colored = np.delete(heatmap_colored, 3, axis=2)  # Drop alpha channel\n",
    "\n",
    "    # Resize the colored heatmap to match the size of the original image\n",
    "    heatmap_colored = Image.fromarray(np.uint8(heatmap_colored * 255))  # Convert to PIL image\n",
    "    heatmap_colored = heatmap_colored.resize(img.size, Image.LANCZOS)  # Resize to match image size\n",
    "    heatmap_colored = np.array(heatmap_colored)  # Convert back to numpy array\n",
    "\n",
    "    # Convert original image to numpy array\n",
    "    img = np.array(img)\n",
    "\n",
    "    # Overlay the heatmap on the image with transparency\n",
    "    overlay = np.uint8(img * (1 - alpha) + heatmap_colored * alpha)\n",
    "\n",
    "    # Display the overlay\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your image\n",
    "input_tensor, image = load_image('/Users/ahmtox/tmp/Homework/CS282r/cs2822r-project/wangzai.jpeg')\n",
    "\n",
    "# Set the model to train mode temporarily to compute gradients\n",
    "model.train()\n",
    "\n",
    "# Forward pass to get model's output\n",
    "with torch.enable_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Get the predicted class (class with the highest score)\n",
    "target_class = output.argmax().item()\n",
    "\n",
    "# Zero out any previous gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# Backward pass to compute gradients for the target class, retain graph for Grad-CAM\n",
    "output[:, target_class].backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize Grad-CAM for multiple layers\n",
    "def generate_gradcam_for_all_layers(activations, target_class, gradients):\n",
    "    for layer_name, activation in activations.items():\n",
    "        # Compute the gradients for each layer\n",
    "        gradients = torch.autograd.grad(output[:, target_class], activation, retain_graph=True)[0]\n",
    "\n",
    "        # Generate the Grad-CAM heatmap using the activations and gradients\n",
    "        heatmap = grad_cam(activation, gradients)\n",
    "\n",
    "        # Visualize the heatmap overlayed on the original image\n",
    "        print(f\"Visualizing Grad-CAM for layer: {layer_name}\")\n",
    "        visualize_heatmap(image, heatmap)\n",
    "\n",
    "# Generate and visualize Grad-CAM heatmaps for all convolutional layers with a colormap\n",
    "generate_gradcam_for_all_layers(activations, target_class, gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
